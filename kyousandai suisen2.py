import streamlit as st
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# ===============================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ===============================
df = pd.read_excel("excel2.xlsx")

# ===============================
# åˆ—å®šç¾©
# ===============================
bunkei_courses = [
    'çµŒæ¸ˆ/çµŒæ¸ˆ', 'çµŒå–¶/ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ', 'æ³•/æ³•å¾‹', 'æ³•/æ³•æ”¿ç­–',
    'ç¾ä»£ç¤¾ä¼š/ç¾ä»£ç¤¾ä¼š', 'ç¾ä»£ç¤¾ä¼š/å¥åº·ã‚¹ãƒãƒ¼ãƒ„ç¤¾ä¼š',
    'å›½éš›é–¢ä¿‚/å›½éš›é–¢ä¿‚',
    'å¤–å›½èª/è‹±èª', 'å¤–å›½èª/ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘è¨€èª', 'å¤–å›½èª/ã‚¢ã‚¸ã‚¢è¨€èª',
    'æ–‡åŒ–/æ–‡åŒ–æ§‹æƒ³', 'æ–‡åŒ–/äº¬éƒ½æ–‡åŒ–', 'æ–‡åŒ–/æ–‡åŒ–è¦³å…‰'
]

rikei_courses = [
    'ç†/æ•°ç†ç§‘', 'ç†/ç‰©ç†ç§‘', 'ç†/å®‡å®™ç‰©ç†ãƒ»æ°—è±¡',
    'æƒ…å ±ç†å·¥/æƒ…å ±ç†å·¥',
    'ç”Ÿå‘½ç§‘/å…ˆç«¯ç”Ÿå‘½ç§‘', 'ç”Ÿå‘½ç§‘/ç”£æ¥­ç”Ÿå‘½ç§‘'
]

course_columns = bunkei_courses + rikei_courses

interest_columns = ['æ—…è¡Œ','èª­æ›¸','éŸ³æ¥½','ã‚¹ãƒãƒ¼ãƒ„','æ˜ ç”»ãƒ»ãƒ‰ãƒ©ãƒ','ã‚²ãƒ¼ãƒ ','ã‚¢ãƒ‹ãƒ¡ãƒ»æ¼«ç”»']
meta_columns = ['æ€§åˆ¥','æ–‡ç†','åå·®å€¤']
character_columns = [
    'ISTJ(ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ã‚·ãƒ£ãƒ³)','ISFJ(æ“è­·è€…)','INFJ(æå”±è€…)','INTJ(å»ºç¯‰å®¶)',
    'ISTP(å·¨åŒ )','ISFP(å†’é™ºå®¶)','INFP(ä»²ä»‹è€…)','INTP(è«–ç†å­¦è€…)',
    'ESTP(èµ·æ¥­å®¶)','ESFP(ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒŠãƒ¼)','ENFP(é‹å‹•å®¶)','ENTP(è¨è«–è€…)',
    'ESTJ(å¹¹éƒ¨)','ESFJ(é ˜äº‹)','ENFJ(ä¸»äººå…¬)','ENTJ(æŒ‡æ®å®˜)'
]
subject_columns = ['å›½èª','æ•°å­¦','è‹±èª','ç†ç§‘','ç¤¾ä¼š']

# ===============================
# UIï¼šé‡ã¿èª¿æ•´
# ===============================
st.sidebar.title("âš™ é‡ã¿èª¿æ•´")
interest_w = st.sidebar.slider("èˆˆå‘³ã®é‡ã¿", 0.5, 5.0, 3.0)
subject_w  = st.sidebar.slider("å¾—æ„ç§‘ç›®ã®é‡ã¿", 0.5, 8.0, 5.0)
mbti_w     = st.sidebar.slider("MBTIã®é‡ã¿", 0.5, 5.0, 2.0)
meta_w     = st.sidebar.slider("å±æ€§ã®é‡ã¿", 0.1, 2.0, 1.0)

# ===============================
# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
# ===============================
course_df = df[course_columns]

features_df = df[
    interest_columns + meta_columns + character_columns + subject_columns
].copy()

# é‡ã¿é©ç”¨
features_df[interest_columns] *= interest_w
features_df[subject_columns]  *= subject_w
features_df[character_columns]*= mbti_w
features_df[meta_columns]     *= meta_w

# ===============================
# å­¦éƒ¨ã”ã¨ã®å¹³å‡å€¤ï¼ˆãƒã‚¤ã‚¢ã‚¹ï¼‰
# ===============================
faculty_map = {
    'çµŒæ¸ˆ': ['çµŒæ¸ˆ/çµŒæ¸ˆ'],
    'çµŒå–¶': ['çµŒå–¶/ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ'],
    'æ³•': ['æ³•/æ³•å¾‹','æ³•/æ³•æ”¿ç­–'],
    'ç¾ä»£ç¤¾ä¼š': ['ç¾ä»£ç¤¾ä¼š/ç¾ä»£ç¤¾ä¼š','ç¾ä»£ç¤¾ä¼š/å¥åº·ã‚¹ãƒãƒ¼ãƒ„ç¤¾ä¼š'],
    'å›½éš›é–¢ä¿‚': ['å›½éš›é–¢ä¿‚/å›½éš›é–¢ä¿‚'],
    'å¤–å›½èª': ['å¤–å›½èª/è‹±èª','å¤–å›½èª/ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘è¨€èª','å¤–å›½èª/ã‚¢ã‚¸ã‚¢è¨€èª'],
    'æ–‡åŒ–': ['æ–‡åŒ–/æ–‡åŒ–æ§‹æƒ³','æ–‡åŒ–/äº¬éƒ½æ–‡åŒ–','æ–‡åŒ–/æ–‡åŒ–è¦³å…‰'],
    'ç†': ['ç†/æ•°ç†ç§‘','ç†/ç‰©ç†ç§‘','ç†/å®‡å®™ç‰©ç†ãƒ»æ°—è±¡'],
    'æƒ…å ±ç†å·¥': ['æƒ…å ±ç†å·¥/æƒ…å ±ç†å·¥'],
    'ç”Ÿå‘½ç§‘å­¦': ['ç”Ÿå‘½ç§‘/å…ˆç«¯ç”Ÿå‘½ç§‘','ç”Ÿå‘½ç§‘/ç”£æ¥­ç”Ÿå‘½ç§‘']
}

faculty_mean = {}
for faculty, cols in faculty_map.items():
    faculty_mean[faculty] = course_df[cols].mean(axis=1).mean()

# ===============================
# æ¨è–¦é–¢æ•°
# ===============================
def recommend_courses(user_features, bunri, top_n=3):
    user_vec = np.array(user_features).reshape(1, -1)
    user_vec = user_vec / (np.linalg.norm(user_vec) + 1e-8)

    X = features_df.values
    X = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)

    similarities = cosine_similarity(user_vec, X)[0]

    # æº€è¶³åº¦ã§é‡ã¿ä»˜ã‘
    satisfaction = df["æº€è¶³åº¦"].values
    satisfaction_weight = satisfaction / satisfaction.max()
    weighted_sim = similarities * satisfaction_weight

    top_k = 50
    top_idx = np.argsort(weighted_sim)[-top_k:]
    top_sim = weighted_sim[top_idx]

    raw_score = (
        np.dot(top_sim, course_df.values[top_idx])
        / (top_sim.sum() + 1e-8)
    )

    score = pd.Series(raw_score, index=course_columns)

    # =========================
    # â˜… å­¦éƒ¨å¹³å‡ã¨ã®å·®ã‚’å¼•ãï¼ˆæœ€é‡è¦ï¼‰
    # =========================
    for faculty, cols in faculty_map.items():
        for col in cols:
            score[col] -= faculty_mean[faculty]

    # æ–‡ç†ãƒ•ã‚£ãƒ«ã‚¿
    if bunri == "æ–‡ç³»":
        score = score[bunkei_courses]
    else:
        score = score[rikei_courses]

    return score.sort_values(ascending=False).head(top_n)

# ===============================
# UI
# ===============================
st.title("ğŸ“ äº¬ç”£å¤§ é€²è·¯æ¨è–¦ï¼ˆãƒŸã‚¹ãƒãƒƒãƒé˜²æ­¢å‹ï¼‰")

user_features = []

st.subheader("â‘  èˆˆå‘³")
for col in interest_columns:
    user_features.append((1 if st.checkbox(col) else 0) * interest_w)

st.subheader("â‘¡ åŸºæœ¬æƒ…å ±")
gender = st.selectbox("æ€§åˆ¥", ["ç”·æ€§","å¥³æ€§"])
bunri = st.selectbox("æ–‡ç†", ["æ–‡ç³»","ç†ç³»"])
hensachi = st.slider("åå·®å€¤", 35, 70, 50)

user_features += [
    (0 if gender=="ç”·æ€§" else 1)*meta_w,
    (0 if bunri=="æ–‡ç³»" else 1)*meta_w,
    (hensachi/100)*meta_w
]

st.subheader("â‘¢ MBTI")
mbti = st.selectbox("MBTI", character_columns)
for col in character_columns:
    user_features.append((1 if col==mbti else 0)*mbti_w)

st.subheader("â‘£ å¾—æ„ç§‘ç›®")
kamoku = st.selectbox("å¾—æ„ç§‘ç›®", subject_columns)
for col in subject_columns:
    user_features.append((1 if col==kamoku else 0)*subject_w)

# ===============================
# å®Ÿè¡Œ
# ===============================
if st.button("é€²è·¯ã‚’æ¨è–¦"):
    result = recommend_courses(user_features, bunri)

    st.subheader("ãŠã™ã™ã‚å­¦ç§‘")
    for i, (name, score) in enumerate(result.items(), 1):
        st.markdown(f"### {i}. {name}")
        st.write(f"ã‚¹ã‚³ã‚¢: {score:.2f}")
        st.write("**ç†ç”±ï¼š**")
        st.write("ãƒ»ã‚ãªãŸã¨ä¼¼ãŸå­¦ç”Ÿã®æº€è¶³åº¦ãŒé«˜ã„")
        st.write("ãƒ»å­¦éƒ¨å…¨ä½“ã®äººæ°—ã«å¼•ã£å¼µã‚‰ã‚Œã¦ã„ãªã„")
